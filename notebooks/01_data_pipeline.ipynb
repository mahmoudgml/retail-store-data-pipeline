{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FoFdkAP4fSlW"
      },
      "source": [
        "# Project: Retail Store Data Pipeline & Analysis\n",
        "\n",
        "In this notebook we will build an end-to-end data pipeline including **data loading, cleaning, transformation, and SQL analysis**.\n",
        "\n",
        "---\n",
        "\n",
        "## Table of Contents\n",
        "\n",
        "1. [Introduction](#intro)  \n",
        "2. [Data Loading](#loading)  \n",
        "3. [Data Wrangling](#wrangling)  \n",
        "4. [Data Transformation](#transformation)\n",
        "5. [SQL Loading](#sql)  \n",
        "6. [Summary](#summary) \n",
        "\n",
        "---\n",
        "\n",
        "<a id='intro'></a>\n",
        "## Introduction\n",
        "\n",
        "### Dataset Description\n",
        "\n",
        "We will work with **retail store data from 2016-2018**. This dataset contains **9 CSV files** with information about products, customers, orders, and inventory.\n",
        "\n",
        "The datasets include:\n",
        "\n",
        "1. **Brands**: Brand information (`brand_id`, `brand_name`)  \n",
        "2. **Categories**: Product categories (`category_id`, `category_name`)  \n",
        "3. **Products**: Product catalog with prices (`product_id`, `product_name`, `brand_id`, `category_id`, `model_year`, `list_price`)  \n",
        "4. **Customers**: Customer information with contact details (`customer_id`, `first_name`, `last_name`, `phone`, `email`, `street`, `city`, `state`, `zip_code`)    \n",
        "5. **Orders**: Order headers (`order_id`, `customer_id`, `order_status`, `order_date`, `required_date`, `shipped_date`, `store_id`, `staff_id`)  \n",
        "6. **Order Items**: Order line items (`order_id`, `item_id`, `product_id`, `quantity`, `list_price`, `discount`)  \n",
        "7. **Staffs**: Store employees (`staff_id`, `first_name`, `last_name`, `email`, `phone`, `active`, `store_id`, `manager_id`)  \n",
        "8. **Stores**: Store locations (`store_id`, `store_name`, `phone`, `email`, `street`, `city`, `state`, `zip_code`)  \n",
        "9. **Stocks**: Inventory levels (`store_id`, `product_id`, `quantity`)  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXA7la23gJo-"
      },
      "source": [
        "<a id='loading'></a>\n",
        "# 1- import packages and load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rZLgaiYxgKVj",
        "outputId": "6b096a9c-7de9-4d12-fbe6-00fdb700dfd9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "brands_df = pd.read_csv(r'D:\\Downloads\\Project\\Data_Sources\\brands.csv')\n",
        "categories_df = pd.read_csv(r'D:\\Downloads\\Project\\Data_Sources\\categories.csv')\n",
        "products_df = pd.read_csv(r'D:\\Downloads\\Project\\Data_Sources\\products.csv')\n",
        "customers_df = pd.read_csv(r'D:\\Downloads\\Project\\Data_Sources\\customers.csv')\n",
        "orders_df = pd.read_csv(r'D:\\Downloads\\Project\\Data_Sources\\orders.csv')\n",
        "order_items_df = pd.read_csv(r'D:\\Downloads\\Project\\Data_Sources\\order_items.csv')\n",
        "staffs_df = pd.read_csv(r'D:\\Downloads\\Project\\Data_Sources\\staffs.csv')\n",
        "stores_df = pd.read_csv(r'D:\\Downloads\\Project\\Data_Sources\\stores.csv')\n",
        "stocks_df = pd.read_csv(r'D:\\Downloads\\Project\\Data_Sources\\stocks.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0zpDBvSj3X6"
      },
      "source": [
        "<a id='wrangling'></a>\n",
        "## Data Wrangling\n",
        "\n",
        "\n",
        "\n",
        "### General Properties"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LaYSSYDAj77J"
      },
      "source": [
        "# 2- show some general properties for the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "IZpjGCpKmBdf",
        "outputId": "340e1f05-58c0-4610-fc09-0ff464996090"
      },
      "outputs": [],
      "source": [
        "#brands_df.head()\n",
        "#categories_df.head()\n",
        "#products_df.head()\n",
        "#customers_df.head(15)\n",
        "#orders_df.head(70)\n",
        "#order_items_df.head()\n",
        "#staffs_df.head(15)\n",
        "#stores_df.head()\n",
        "#stocks_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96IBiMOij8bQ",
        "outputId": "1b282d96-0a6f-431c-b376-1148a96ae8ee"
      },
      "outputs": [],
      "source": [
        "print(\"DATASET SHAPES:\")\n",
        "print(f\"Brands: {brands_df.shape}\")\n",
        "print(f\"Categories: {categories_df.shape}\")\n",
        "print(f\"Products: {products_df.shape}\")\n",
        "print(f\"Customers: {customers_df.shape}\")\n",
        "print(f\"Orders: {orders_df.shape}\")\n",
        "print(f\"Order Items: {order_items_df.shape}\")\n",
        "print(f\"Staffs: {staffs_df.shape}\")\n",
        "print(f\"Stores: {stores_df.shape}\")\n",
        "print(f\"Stocks: {stocks_df.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-IgYcv25lJcR",
        "outputId": "51de5ec1-8267-442e-9aef-d899ccbceb76"
      },
      "outputs": [],
      "source": [
        "print(\"\\n DATA TYPES:\")\n",
        "print(\"\\n Brands columns:\")\n",
        "print(brands_df.dtypes)\n",
        "print(\"\\n Categories columns:\")\n",
        "print(categories_df.dtypes)\n",
        "print(\"\\n Products columns:\")\n",
        "print(products_df.dtypes)\n",
        "print(\"\\n Customers columns:\")\n",
        "print(customers_df.dtypes)\n",
        "print(\"\\n Orders columns:\")\n",
        "print(orders_df.dtypes)\n",
        "print(\"\\n Order Items columns:\")\n",
        "print(order_items_df.dtypes)\n",
        "print(\"\\n Staffs columns:\")\n",
        "print(staffs_df.dtypes)\n",
        "print(\"\\n Stores columns:\")\n",
        "print(stores_df.dtypes)\n",
        "print(\"\\n Stocks columns:\")\n",
        "print(stocks_df.dtypes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "438OSh-lm2sw",
        "outputId": "ea02d57b-4d0c-495c-ee81-34fed89afa85"
      },
      "outputs": [],
      "source": [
        "print(\"\\n MISSING VALUES:\")\n",
        "\n",
        "print(\"\\n Brands:\")\n",
        "print(brands_df.isna().sum())\n",
        "\n",
        "print(\"\\n Categories:\")\n",
        "print(categories_df.isna().sum())\n",
        "\n",
        "print(\"\\n Products:\")\n",
        "print(products_df.isna().sum())\n",
        "\n",
        "print(\"\\n Customers:\")\n",
        "print(customers_df.isna().sum())\n",
        "\n",
        "print(\"\\n Orders:\")\n",
        "print(orders_df.isna().sum())\n",
        "\n",
        "print(\"\\n Order Items:\")\n",
        "print(order_items_df.isna().sum())\n",
        "\n",
        "print(\"\\n Staffs:\")\n",
        "print(staffs_df.isna().sum())\n",
        "\n",
        "print(\"\\nStores:\")\n",
        "print(stores_df.isna().sum())\n",
        "\n",
        "print(\"\\n Stocks:\")\n",
        "print(stocks_df.isna().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "za7MGZBRSibj",
        "outputId": "63db9a51-495c-415a-def5-47f1c4a7f2ac"
      },
      "outputs": [],
      "source": [
        "print(\"DATASET DUPLICATES:\")\n",
        "print(f\"Brands: {brands_df.duplicated().sum()}\")\n",
        "print(f\"Categories: {categories_df.duplicated().sum()}\")\n",
        "print(f\"Products: {products_df.duplicated().sum()}\")\n",
        "print(f\"Customers: {customers_df.duplicated().sum()}\")\n",
        "print(f\"Orders: {orders_df.duplicated().sum()}\")\n",
        "print(f\"Order Items: {order_items_df.duplicated().sum()}\")\n",
        "print(f\"Staffs: {staffs_df.duplicated().sum()}\")\n",
        "print(f\"Stores: {stores_df.duplicated().sum()}\")\n",
        "print(f\"Stocks: {stocks_df.duplicated().sum()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OeUp8frmn7cv"
      },
      "source": [
        "# 3- Summary of results from previous functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BKSGfdNwn8Ce"
      },
      "outputs": [],
      "source": [
        "print(\"\"\"\n",
        "Cleaned DataFrames:\n",
        "\n",
        "- Brand DataFrame\n",
        "- Categories DataFrame\n",
        "\n",
        "\n",
        "DataFrames needing cleaning:\n",
        "\n",
        "1- Products DataFrame\n",
        "- DUPLICATES: remove\n",
        "\n",
        "2- Customers DataFrame\n",
        "- MISSING VALUES: 'phone' have NaNs\n",
        "- FORMAT ISSUES: Phone numbers may have multiple values, spaces, special characters\n",
        "- MISSING CALCULATED COLUMN: Need 'full_name'\n",
        "\n",
        "3- Orders DataFrame\n",
        "- MISSING VALUES: 'shipped_date' have NaNs\n",
        "- WRONG DATA TYPES: order_date ,required_date ,shipped_date ,stored as text instead of datetime\n",
        "\n",
        "4- Order Items DataFrame\n",
        "- DUPLICATES: remove\n",
        "- WRONG RANGE OF VALUES: Quantities may be negative\n",
        " In the transformation:\n",
        " - MISSING CALCULATED COLUMN: Need 'total_price'\n",
        "\n",
        "5- Staffs DataFrame\n",
        "- MISSING VALUES: 'phone','email','last_name ,'store_id','manager_id' have NaNs\n",
        "- drop 'store_id','manager_id' (Reason: these columns contain too many missing values and are not useful for analysis)\n",
        "- FORMAT ISSUES: Phone numbers may have multiple values, spaces, special characters\n",
        "\n",
        "6- Stores DataFrame\n",
        "- MISSING VALUES: 'zip_code','email' have NaNs\n",
        "- WRONG DATA TYPES: 'zip_code' stored as float instead of string (to allow filling with 'Unknown')\n",
        "- FORMAT ISSUES: Phone numbers may have multiple values, spaces, special characters\n",
        "\n",
        "7- Stocks DataFrame\n",
        "- WRONG RANGE OF VALUES: Quantities may be negative\n",
        "\"\"\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3G04ZrqUwYd4"
      },
      "source": [
        "# cleaning\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vw-CVR7lwg9C"
      },
      "source": [
        "### 4- Standardize Column Names\n",
        "> Tip: Convert all column names to lowercase and replace spaces with underscores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vlzPvXvkwiM-"
      },
      "outputs": [],
      "source": [
        "brands_df.columns = brands_df.columns.str.lower().str.replace(' ', '_')\n",
        "categories_df.columns = categories_df.columns.str.lower().str.replace(' ', '_')\n",
        "products_df.columns = products_df.columns.str.lower().str.replace(' ', '_')\n",
        "customers_df.columns = customers_df.columns.str.lower().str.replace(' ', '_')\n",
        "orders_df.columns = orders_df.columns.str.lower().str.replace(' ', '_')\n",
        "order_items_df.columns = order_items_df.columns.str.lower().str.replace(' ', '_')\n",
        "staffs_df.columns = staffs_df.columns.str.lower().str.replace(' ', '_')\n",
        "stores_df.columns = stores_df.columns.str.lower().str.replace(' ', '_')\n",
        "stocks_df.columns = stocks_df.columns.str.lower().str.replace(' ', '_')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxh5Qq2UUiZr"
      },
      "source": [
        "### 5 - clean  ` products ` Table\n",
        "> Tip: Remove duplicates\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y44BJtaEU7_C"
      },
      "outputs": [],
      "source": [
        "products_df = products_df.drop_duplicates()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbhe5vUFxJgu"
      },
      "source": [
        "### 6 - clean ` Customers ` Table\n",
        "> Tip: Handle missing phone , clean phone numbers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xEDTuEMGyZaF"
      },
      "outputs": [],
      "source": [
        "customers_df['phone'] = customers_df['phone'].fillna('Unknown')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-qKrfbi_zBYS"
      },
      "outputs": [],
      "source": [
        "def clean_phone(phone):\n",
        "  if phone == 'Unknown':\n",
        "        return phone\n",
        "  if ',' in phone:\n",
        "        phone = phone.split(',')[0]\n",
        "  phone = ''.join(filter(str.isdigit, phone))\n",
        "  return phone\n",
        "\n",
        "customers_df['phone'] = customers_df['phone'].apply(clean_phone)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "OV1pfgyDzHjC",
        "outputId": "2accdb4d-46c1-4811-8408-124faa2330b2"
      },
      "outputs": [],
      "source": [
        "customers_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGRsm8S53B6j"
      },
      "source": [
        "### 7 - clean ` Orders ` Table\n",
        "> Tip: Convert dates to datetime ,\n",
        "After converting date columns to datetime -->Drop rows where order_date is missing (because the order cannot exist without a valid order date) , \n",
        "After converting date columns to datetime --> missing values in required_date were left as NULL to avoid introducing incorrect assumptions, Handle missing shipped_date"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RREuxC8-3J8B"
      },
      "outputs": [],
      "source": [
        "orders_df['order_date'] = pd.to_datetime(orders_df['order_date'], errors='coerce')\n",
        "orders_df['required_date'] = pd.to_datetime(orders_df['required_date'], errors='coerce')\n",
        "orders_df['shipped_date'] = pd.to_datetime(orders_df['shipped_date'], errors='coerce')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YJdQaAzhMyGC"
      },
      "outputs": [],
      "source": [
        "orders_df = orders_df.dropna(subset=['order_date'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F0kAR4i9HQoK"
      },
      "outputs": [],
      "source": [
        "orders_df['shipped_date'] = orders_df['shipped_date'].fillna(orders_df['required_date'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_XBnMBXGx-C",
        "outputId": "5ddc16b6-8530-48c8-bfda-b7e4cab76f8d"
      },
      "outputs": [],
      "source": [
        "orders_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xIhXky5L6Sp_"
      },
      "source": [
        "### 8 - clean `  Order Items ` Table\n",
        "> Tip: Remove duplicates , Remove negative quantities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3qrE0YIp6grO"
      },
      "outputs": [],
      "source": [
        "order_items_df = order_items_df.drop_duplicates()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rtRmMAx3FfFr"
      },
      "outputs": [],
      "source": [
        "order_items_df = order_items_df[order_items_df['quantity'] > 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Ik_x2sywFnkP",
        "outputId": "754af58f-65f6-470e-fd4b-ece176f89952"
      },
      "outputs": [],
      "source": [
        "order_items_df.head()   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8_otGWV_gAU"
      },
      "source": [
        "### 9 - clean `   Staffs ` Table\n",
        "> Tip:  Handle missing phone and email and last_name , dropna store_id and manager_id , clean phone numbers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aLUwauhv_yZ5"
      },
      "outputs": [],
      "source": [
        "staffs_df['phone'] = staffs_df['phone'].fillna('Unknown')\n",
        "staffs_df['email'] = staffs_df['email'].fillna('unknown@email.com')\n",
        "staffs_df['last_name'] = staffs_df['last_name'].fillna('Unknown')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dZER8AeGMBJ2"
      },
      "outputs": [],
      "source": [
        "staffs_df['phone'] = staffs_df['phone'].apply(clean_phone)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "T9FffdL9H2Vj",
        "outputId": "12e8bfcc-cc6d-4a5e-9206-8a30bb52033d"
      },
      "outputs": [],
      "source": [
        "staffs_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eTIAUs9Bm5Z"
      },
      "source": [
        "### 10 - clean `  Stores ` Table\n",
        "> Tip:  Handle missing email and phone , Convert zip_code to string and Handle missing , clean phone numbers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IEplGE-mB1l4"
      },
      "outputs": [],
      "source": [
        "stores_df['email'] = stores_df['email'].fillna('unknown@email.com')\n",
        "stores_df['phone'] = stores_df['phone'].fillna('Unknown')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lvo_Ts2TNrD9"
      },
      "outputs": [],
      "source": [
        "stores_df['zip_code'] = stores_df['zip_code'].astype('string')\n",
        "stores_df['zip_code'] = stores_df['zip_code'].fillna(\"Unknown\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EBlKOlaMO0Ps"
      },
      "outputs": [],
      "source": [
        "stores_df['phone'] = stores_df['phone'].apply(clean_phone)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "7J1_LS_PNs1t",
        "outputId": "eeb0ab9c-a7da-4d1d-c5ec-3602ff405117"
      },
      "outputs": [],
      "source": [
        "stores_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2iJpGK-AIkWb"
      },
      "source": [
        "### 11 - clean `  Stocks ` Table\n",
        "> Tip: Remove negative quantities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XHi6jYTPWW46"
      },
      "outputs": [],
      "source": [
        "stocks_df = stocks_df[stocks_df['quantity'] > 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "stocks_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMV27W6jEccg"
      },
      "source": [
        "<a id='transformation'></a>\n",
        "## Data Transformation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDpX-M_YZ7wW"
      },
      "source": [
        "### 12 - Merge products with brands and categories\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0i5xEuB4ezWg"
      },
      "source": [
        "we will merge the `products_df` with `brands_df` and `categories_df`  \n",
        "to have a single DataFrame containing all product information along with the brand name and category name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FTdJ4nx0Zzmk"
      },
      "outputs": [],
      "source": [
        "products_merged = products_df.merge(brands_df, on='brand_id', how='left')\n",
        "products_merged = products_merged.merge(categories_df, on='category_id', how='left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "wgE3H5NCbXWa",
        "outputId": "745ea6bc-9131-4e64-b9d7-2c9906903b6c"
      },
      "outputs": [],
      "source": [
        "products_merged.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFVq50fwEojG"
      },
      "source": [
        "### 13 - Calculate total_price for Order Items\n",
        "> Tip: total_price = quantity * list_price"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pmYloLEhEx4u"
      },
      "outputs": [],
      "source": [
        "order_items_df['total_price'] = order_items_df['quantity'] * order_items_df['list_price']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "vGCVG-iiSRYi",
        "outputId": "b81989ad-2b32-4f68-834a-e04594b82146"
      },
      "outputs": [],
      "source": [
        "order_items_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBCbEV4nGHjm"
      },
      "source": [
        "### 14- Calculate Order Total Amount\n",
        "> Tip: Group by order_id and sum total_price"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZsOI8PbAGRO0"
      },
      "outputs": [],
      "source": [
        "order_totals =(order_items_df\n",
        "               .groupby('order_id')\n",
        "               ['total_price'].sum()\n",
        "               .reset_index()\n",
        "               )\n",
        "order_totals.columns = ['order_id', 'order_total_amount']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "O3kkeWcMXS9F",
        "outputId": "249d7905-15e8-46d0-9b91-2531fe4c6a7f"
      },
      "outputs": [],
      "source": [
        "order_totals"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 15 - create  customer full_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "customers_df['full_name'] = customers_df['first_name'] + ' ' + customers_df['last_name']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "customers_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PX1gdn7TGb9e"
      },
      "source": [
        "### 16 - Save Cleaned Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U1pzttsFGgPU"
      },
      "outputs": [],
      "source": [
        "brands_df.to_csv(r'D:\\Downloads\\Project\\Cleaned_datasets\\cleaned_brands.csv', index=False)\n",
        "categories_df.to_csv(r'D:\\Downloads\\Project\\Cleaned_datasets\\cleaned_categories.csv', index=False)\n",
        "products_df.to_csv(r'D:\\Downloads\\Project\\Cleaned_datasets\\cleaned_products.csv', index=False)\n",
        "customers_df.to_csv(r'D:\\Downloads\\Project\\Cleaned_datasets\\cleaned_customers.csv', index=False)\n",
        "orders_df.to_csv(r'D:\\Downloads\\Project\\Cleaned_datasets\\cleaned_orders.csv', index=False)\n",
        "order_items_df.to_csv(r'D:\\Downloads\\Project\\Cleaned_datasets\\cleaned_order_items.csv', index=False)\n",
        "staffs_df.to_csv(r'D:\\Downloads\\Project\\Cleaned_datasets\\cleaned_staffs.csv', index=False)\n",
        "stores_df.to_csv(r'D:\\Downloads\\Project\\Cleaned_datasets\\cleaned_stores.csv', index=False)\n",
        "stocks_df.to_csv(r'D:\\Downloads\\Project\\Cleaned_datasets\\cleaned_stocks.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nq-mYkd5vb3-"
      },
      "source": [
        "### 17 - Final Check"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k92eG8-Vvgst"
      },
      "source": [
        "\n",
        "> After finishing cleaning and loading, make sure:\n",
        "   *   There is no wrong data type\n",
        "   *   There is no NaN values (or handled appropriately)\n",
        "   *   All columns are clean and ready for analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zCDHvKW9vmg2",
        "outputId": "405170da-6d41-4db7-eb9b-28e6926939df"
      },
      "outputs": [],
      "source": [
        "\n",
        "print(\"   FINAL CHECK   \")\n",
        "\n",
        "print(\"\\n Dataset Shapes:\")\n",
        "print(f\"Brands: {brands_df.shape}\")\n",
        "print(f\"Categories: {categories_df.shape}\")\n",
        "print(f\"Products: {products_df.shape}\")\n",
        "print(f\"Customers: {customers_df.shape}\")\n",
        "print(f\"Orders: {orders_df.shape}\")\n",
        "print(f\"Order Items: {order_items_df.shape}\")\n",
        "print(f\"Staffs: {staffs_df.shape}\")\n",
        "print(f\"Stores: {stores_df.shape}\")\n",
        "print(f\"Stocks: {stocks_df.shape}\")\n",
        "\n",
        "print(\"\\n Total Missing Values:\")\n",
        "print(f\"Brands: {brands_df.isna().sum().sum()}\")\n",
        "print(f\"Categories: {categories_df.isna().sum().sum()}\")\n",
        "print(f\"Products: {products_df.isna().sum().sum()}\")\n",
        "print(f\"Customers: {customers_df.isna().sum().sum()}\")\n",
        "print(f\"Orders: {orders_df.isna().sum().sum()}\")\n",
        "print(f\"Order Items: {order_items_df.isna().sum().sum()}\")\n",
        "print(f\"Staffs: {staffs_df.isna().sum().sum()}\")\n",
        "print(f\"Stores: {stores_df.isna().sum().sum()}\")\n",
        "print(f\"Stocks: {stocks_df.isna().sum().sum()}\")\n",
        "\n",
        "print(\"\\n Data Types Check:\")\n",
        "print(\"Customers:\", customers_df.dtypes.tolist())\n",
        "print(\"Orders:\", orders_df.dtypes.tolist())\n",
        "print(\"Order Items:\", order_items_df.dtypes.tolist())\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhgE4Y4KGoNF"
      },
      "source": [
        "<a id='sql'></a>\n",
        "## Load to SQL Server"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gm9Kz703G4Oe"
      },
      "source": [
        "### 1 - Connect to SQL Server"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iw2De18wGv38"
      },
      "outputs": [],
      "source": [
        "from sqlalchemy import create_engine\n",
        "from urllib.parse import quote_plus\n",
        "\n",
        "SERVER = r\"GEMY\"\n",
        "DATABASE = \"RetailDB\"\n",
        "ODBC_DRIVER = \"ODBC Driver 17 for SQL Server\"\n",
        "\n",
        "conn_str = (\n",
        "    f\"DRIVER={{{ODBC_DRIVER}}};\"\n",
        "    f\"SERVER={SERVER};\"\n",
        "    f\"DATABASE={DATABASE};\"\n",
        "    \"Trusted_Connection=yes;\"\n",
        ")\n",
        "\n",
        "engine = create_engine(\n",
        "    \"mssql+pyodbc:///?odbc_connect=%s\" % quote_plus(conn_str),\n",
        "    fast_executemany=True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NlKj5WbuHBHF"
      },
      "source": [
        "### 2 - Load Tables to SQL Server"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with engine.begin() as conn:\n",
        "    brands_df.to_sql('Brands', conn, if_exists='append', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with engine.begin() as conn:\n",
        "    categories_df.to_sql('Categories', conn, if_exists='append', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with engine.begin() as conn:\n",
        "    products_df.to_sql('Products', conn, if_exists='append', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with engine.begin() as conn:\n",
        "    stores_df.to_sql('Stores', conn, if_exists='append', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a copy of the DataFrame to avoid modifying the original one\n",
        "staffs_df = staffs_df.copy()\n",
        "\n",
        "# -------------------------------\n",
        "# 1. Fix store_id issues\n",
        "# Keep only rows where the store_id exists in the Stores table\n",
        "# If a store_id is not found in stores_df, that staff row will be removed\n",
        "staffs_df = staffs_df[staffs_df['store_id'].isin(stores_df['store_id'])]\n",
        "\n",
        "# -------------------------------\n",
        "# 2. Fix manager_id issues\n",
        "# If manager_id is NaN or does not match any staff_id, set it to None\n",
        "# SQL Server will interpret None as NULL\n",
        "staffs_df['manager_id'] = staffs_df['manager_id'].where(\n",
        "    staffs_df['manager_id'].isin(staffs_df['staff_id']), None\n",
        ")\n",
        "\n",
        "# -------------------------------\n",
        "# 3. Convert columns to integer\n",
        "# We can safely convert store_id and staff_id to int because there are no NaN values\n",
        "staffs_df['store_id'] = staffs_df['store_id'].astype(int)\n",
        "staffs_df['staff_id'] = staffs_df['staff_id'].astype(int)\n",
        "\n",
        "# -------------------------------\n",
        "# 4. Upload the cleaned DataFrame to SQL Server\n",
        "with engine.begin() as conn:\n",
        "    staffs_df.to_sql('Staffs', conn, if_exists='append', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "customers_df = customers_df.drop(columns=['full_name'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with engine.begin() as conn:\n",
        "    customers_df.to_sql('Customers', conn, if_exists='append', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with engine.begin() as conn:\n",
        "    orders_df.to_sql('Orders', conn, if_exists='append', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "order_items_df = order_items_df.drop(columns=['total_price'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "orders_in_db = pd.read_sql(\"SELECT order_id FROM Orders\", engine)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Keep only rows where order_id exists in the Orders table\n",
        "# This avoids foreign key constraint errors in SQL Server\n",
        "valid_order_items = order_items_df[order_items_df['order_id'].isin(orders_in_db['order_id'])]\n",
        "\n",
        "# -------------------------------\n",
        "# Print how many rows are valid and how many will be rejected\n",
        "print(f\"Number of valid rows to insert: {len(valid_order_items)}\")  # Number of valid rows\n",
        "print(f\"Number of rows that will be rejected: {len(order_items_df) - len(valid_order_items)}\")  # Number of rejected rows\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with engine.begin() as conn:\n",
        "    valid_order_items.to_sql('OrderItems', conn, if_exists='append', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with engine.begin() as conn:\n",
        "    stocks_df.to_sql('Stocks', conn, if_exists='append', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id='summary'></a>\n",
        "### Write a Summary About All the Cleaning Steps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\"\"\n",
        "DATA CLEANING SUMMARY\n",
        "\n",
        "1. LOADED DATA:\n",
        "   - Loaded 9 CSV files successfully\n",
        "   - Checked shapes and data types and missing,duplicates values\n",
        "\n",
        "2. STANDARDIZED COLUMN NAMES:\n",
        "   - Converted all column names to lowercase\n",
        "   - Replaced spaces with underscores\n",
        "      \n",
        "3. Cleaned DataFrames:\n",
        "\n",
        "   - Brand DataFrame\n",
        "   - Categories DataFrame\n",
        "\n",
        "\n",
        "4. DataFrames needing cleaning:\n",
        "\n",
        "    1- Products DataFrame\n",
        "    - DUPLICATES: remove\n",
        "\n",
        "    2- Customers DataFrame\n",
        "    - MISSING VALUES: 'phone' have NaNs\n",
        "    - FORMAT ISSUES: Phone numbers may have multiple values, spaces, special characters\n",
        "    - MISSING CALCULATED COLUMN: Need 'full_name'\n",
        "\n",
        "    3- Orders DataFrame\n",
        "    - MISSING VALUES: 'shipped_date' have NaNs\n",
        "    - WRONG DATA TYPES: order_date ,required_date ,shipped_date ,stored as text instead of datetime\n",
        "\n",
        "    4- Order Items DataFrame\n",
        "    - DUPLICATES: remove\n",
        "    - WRONG RANGE OF VALUES: Quantities may be negative\n",
        "    In the transformation:\n",
        "        - MISSING CALCULATED COLUMN: Need 'total_price'\n",
        "\n",
        "    5- Staffs DataFrame\n",
        "    - MISSING VALUES: 'phone','email','last_name ,'store_id','manager_id' have NaNs\n",
        "    - drop 'store_id','manager_id' (Reason: these columns contain too many missing values and are not useful for analysis)\n",
        "    - FORMAT ISSUES: Phone numbers may have multiple values, spaces, special characters\n",
        " \n",
        "    6- Stores DataFrame\n",
        "    - MISSING VALUES: 'zip_code','email' have NaNs\n",
        "    - WRONG DATA TYPES: 'zip_code' stored as float instead of string (to allow filling with 'Unknown')\n",
        "    - FORMAT ISSUES: Phone numbers may have multiple values, spaces, special characters\n",
        "\n",
        "    7- Stocks DataFrame\n",
        "    - WRONG RANGE OF VALUES: Quantities may be negative\n",
        "\n",
        "4. DATA TRANSFORMATION:\n",
        "    - Calculated total_price for each order item\n",
        "    - Calculated order_total_amount for each order\n",
        "    - Created full_name for customers\n",
        "\n",
        "5. SAVED CLEANED DATA:\n",
        "    - Exported all tables as CSV files\n",
        "    - Loaded all tables to SQL Server\n",
        "\"\"\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
